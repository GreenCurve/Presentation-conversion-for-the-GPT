{'slide_number': 1, 'text': 'Introduction to Machine Learning\nand Data Mining\nGradient Descent for\nLinear and Logistic Regression'}
{'slide_number': 2, 'text': 'Data mining techniques\nSupervised: Labeled data Unsupervised: Unlabeled data\nClassification Numerical prediction Association rules Clustering\nLinear\nDecision trees Apriori Hierarchical\nregression\nClassification Regression /\nFP-growth K-means\nrules model trees\nNaive Bayes\nKNN ‚Ä¶ DBscan\nclassifier\nKNN SVM ‚Ä¶\nSVM ANN\nANN ‚Ä¶\n‚Ä¶'}
{'slide_number': 3, 'text': 'Numeric Prediction'}
{'slide_number': 4, 'text': 'Numeric Prediction'}
{'slide_number': 5, 'text': 'Numeric prediction in Orange\nModels\nMetrics\n‚Ä¢ MSE ‚Äì mean squared error\n‚Ä¢ RMSE ‚Äì root mean squared error\n‚Ä¢ MAE ‚Äì mean absolute error\n‚Ä¢ R2‚Äì correlation coefficient'}
{'slide_number': 6, 'text': 'Numeric prediction is SciKit\n‚Ä¢ Linear Regression:\nfrom sklearn.linear_model import LinearRegression\n‚Ä¢ Ridge Regression:\nfrom sklearn.linear_model import Ridge\n‚Ä¢ Lasso Regression:\nfrom sklearn.linear_model import Lasso\n‚Ä¢ Elastic Net: from\nsklearn.linear_model import ElasticNet\n‚Ä¢ Support Vector Regression (SVR):\nfrom sklearn.svm import SVR\n‚Ä¢ Decision Tree Regression:\nfrom sklearn.tree import DecisionTreeRegressor\n‚Ä¢ Random Forest Regression:\nfrom sklearn.ensemble import RandomForestRegressor\n‚Ä¢ Gradient Boosting Regression:\nfrom sklearn.ensemble import GradientBoostingRegressor\n‚Ä¢ K-Nearest Neighbors Regression (KNN):\nfrom sklearn.neighbors import KNeighborsRegressor\n‚Ä¢ Neural Network Regression:\nfrom sklearn.neural_network import MLPRegressor'}
{'slide_number': 7, 'text': 'Linear Regression\nNotation:\n‚Ä¢ m number of examples\n‚Ä¢ n number of features\n‚Ä¢ ùë¶‡∑ú is the predicted value'}
{'slide_number': 8, 'text': 'Linear Regression\n‚Ä¢ The general formula for a linear function in the context of linear regression can be\nexpressed as:'}
{'slide_number': 9, 'text': 'Single Feature Linear Equation\nFor a simpler form with a single feature, the equation is:'}
{'slide_number': 10, 'text': 'Linear Regression Problem Definition'}
{'slide_number': 11, 'text': 'Ordinary Least Squares (OLS): Closed Form Solution'}
{'slide_number': 12, 'text': 'Computational Complexity of the Closed Form Solution'}
{'slide_number': 13, 'text': 'Gradient Descent\nGradient descent is a fundamental algorithm in machine learning used to optimize models by\nminimizing the cost function, which quantifies the error between predicted and actual values. It\niteratively adjusts model parameters by moving in the direction of the negative gradient, guiding\nthe parameters toward values that reduce the error. This method is particularly useful when\nanalytic solutions are infeasible, making it essential for training models like linear regression,\nlogistic regression, and neural networks.'}
{'slide_number': 14, 'text': ''}
{'slide_number': 15, 'text': 'Finding the Minimum of a Function\nhttps://github.com/pvigier/gradient-descent'}
{'slide_number': 16, 'text': 'Gradient Descent in Machine Learning\nGradient descent is an optimization algorithm used to minimize the error of a function by\niteratively adjusting the values of its parameters. In machine learning, it is commonly used\nto update the weights of a neural network during training in order to minimize the\ndifference between the predicted output and the actual output.\nThe basic idea behind gradient descent is to take small steps in the direction of steepest\ndescent of the function. The steepest descent is given by the negative of the gradient of\nthe function with respect to its parameters. By repeatedly taking small steps in the\ndirection of the negative gradient, we can move towards the minimum of the function.\nGradient descent is also commonly used for linear and logistic regression in machine\nlearning: to find the values of the slope(s) and intersect of the best fitting line (hyperplane).'}
{'slide_number': 17, 'text': 'Gradient Descent for Linear Regression\nIn linear regression, the goal is to find the\na b\nbest-fitting line through a set of data points\nby minimizing the difference between the\npredicted values and the actual values. This\ndifference is measured using the mean\nsquared error (MSE) loss function.\nhttps://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931'}
{'slide_number': 18, 'text': 'Gradient Descent for Linear Regression: MSE\n1. Find the difference between the actual y and predicted yÃÇ value(yÃÇ = ax + b), for a given x.\n2. Square this difference.\n3. Find the mean of the squares for all m examples'}
{'slide_number': 19, 'text': 'Gradient Descent for Linear Regression: MSE\n1. Find the difference between the actual y and predicted yÃÇ value(yÃÇ = mx + c), for a given x.\n2. Square this difference.\n3. Find the mean of the squares for every value in X.\nWhat is fixed for a given dataset?\nWhich parameters are we fitting?'}
{'slide_number': 20, 'text': 'Gradient Descent for Linear Regression: the Gradient\nTo minimize our loss function l = MSE,\nwe adjust parameters a and b.\nCalculating the gradient of the loss\nfunction with respect to these\nparameters helps us determine whether\nto increase or decrease their values.\nWe obtain the gradient by computing\nthe partial derivatives of the loss with\nrespect to a and b (denoted as d \u200b and\na\nd ).\nb\nRemember:'}
{'slide_number': 21, 'text': 'Gradient Descent for Linear Regression: the Gradient\nThe gradient is the partial derivative of the error with respect to the parameters a and b.'}
{'slide_number': 22, 'text': 'Gradient Descent for Linear Regression: the Descent\nThe derivative indicates how much the function changes with a small step.\n‚Ä¢ A positive derivative ‚Üí Error increases.\n‚Ä¢ We need to step in the opposite direction of the positive derivative.\nHow large is the step?\n‚Ä¢ The step size is determined by the learning rate ùêø multiplied by the derivative ùê∑.\n‚Ä¢ The step size is large in steep regions and small in flatter areas.'}
{'slide_number': 23, 'text': 'Gradient Descent for Linear Regression: the Descent\nThe process of updating the parameters is repeated until the algorithm converges to a\nminimum of the loss function.\nThe learning rate, which controls the step size of each update, is an important\nhyperparameter that can affect the speed and performance of the algorithm.'}
{'slide_number': 24, 'text': 'Setting the Learning Rate\n‚Ä¢ If the learning rate is too low\n‚Ä¢ Progress is slow\n‚Ä¢ With a small learning rate, the cost function should\ndecrease in every iteration\n‚Ä¢ If the learning rate is too large\n‚Ä¢ Overshoot, fail to reach the minimum\n‚Ä¢ Fail to converge = diverge\n‚Ä¢ Make sure that your data is scaled:\n‚Ä¢ Mean normalization\n‚Ä¢ Z-score normalization'}
{'slide_number': 25, 'text': 'Setting the Learning Rate in Practice\nLearning Curve\n‚Ä¢ A learning curve shows how a model‚Äôs\nperformance improves over time as it is trained\nthrough additional iterations.\n‚Ä¢ In practice, try learning rate values:\n‚Ä¢ 0.001, 0.003, 0.01, 0.03, 0.1, 0.3\n‚Ä¢ If the loss decreases monotonically, increase\nthe learning rate'}
{'slide_number': 26, 'text': 'Vectorization\n‚Ä¢ Converting scalar operations into vector operations.\n‚Ä¢ Instead of iterating through individual data points, operations are applied to entire arrays\nor matrices.\nBenefits:\n‚Ä¢ Increased Performance (use of low-level libraries)\n‚Ä¢ Enhanced Readability'}
{'slide_number': 27, 'text': 'def gradient_descent(data_x, data_y, iterations=500, learning_rate=0.05):\n"""gradient_descent(data_x, data_y, iterations, learning_rate) -> slope, intercept\nlinear regression by using the gradient descent algorithm"""\nN = len(data_x)\nm, c = 0, 0 # initial values for m and c\nfor _ in range(iterations):\n# Compute the current error\ny = data_x * m + c # predicted value\nerror = data_y - y # vector of differences between predicted and actual\n# Compute the gradient using vectorized operations\ndm = -2/N * np.dot(error, data_x)\ndc = -2/N * np.sum(error)\n# Update m and c\nm = m - dm * learning_rate\nc = c - dc * learning_rate\nreturn m, c\nSee notebook gradient_descent.ipynb for details.'}
{'slide_number': 28, 'text': 'Multiple linear regression\n‚Ä¢ The vectorized version\ntranslates naturally to the case\nwith multiple features.\n‚Ä¢ ùë§ is the bias (intercept)\n0\n‚Ä¢ ùëõ features\n‚Ä¢ ùëö examples'}
{'slide_number': 29, 'text': 'Iterations of gradient descent for Linear Regression\nSee notebook gradient_descent.ipynb for details.'}
{'slide_number': 30, 'text': 'Stochastic and Mini-batch Stochastic Gradient Descent\n‚Ä¢ Batch Gradient Descent\n‚Ä¢ Use all the data at every iteration\n‚Ä¢ Stochastic Gradient Descent (SGD)\n‚Ä¢ Uses one training example per weight update.\n‚Ä¢ Provides frequent updates, leading to faster convergence.\n‚Ä¢ Mini-batch Stochastic Gradient Descent\n‚Ä¢ Utilizes a predefined subset of training data (mini-batch) for each iteration.\n‚Ä¢ Mini-batch size is typically much smaller than the total dataset.'}
{'slide_number': 31, 'text': 'Logistic Regression'}
{'slide_number': 32, 'text': 'Linear Regression for Binary Classification ????\n‚Ä¢ Can we fit a linear regression\nto this problem?\n‚Ä¢ Problem: Outliers far from the\ndecision boundary change the\nboundary\n‚Ä¢ Sigmoid (logistic) function'}
{'slide_number': 33, 'text': 'Sigmoid (Logistic) Function\n‚Ä¢ Outputs is bound to 0 < ùëî(z) < 1\n‚Ä¢ S-shape: Symmetric, smooth curve\n‚Ä¢ Monotonic: Always increasing\n‚Ä¢ Asymptotes:\n‚Ä¢ Approaches 0 as ùëß‚Üí‚àí‚àû\n‚Ä¢ Approaches 1 as ùëß‚Üí‚àû\n‚Ä¢ Midpoint: ùëî(0)=0.5\n‚Ä¢ Derivative: ùëî‚Ä≤(ùëß)=ùëî(ùëß)‚ãÖ(1‚àíùëî(ùëß))\n‚Ä¢ Use: Common in binary classification (maps\nlinear outputs to probabilities).'}
{'slide_number': 34, 'text': 'Sigmoid (Logistic) Function\nThe linear regression model fits into the\nlogistic regression, where ùëß is the result\nof the weighted sum of inputs, and the\nsigmoid function maps this ùëß to a\nprobability.'}
{'slide_number': 35, 'text': 'Cost Function for Logistic Regression\nMSE is not a good cost function for logistic regression because it is not convex\nMSE for Linear Regression MSE for Logistic Regression'}
{'slide_number': 36, 'text': 'Cost Function for Logistic Regression\nBinary Cross-Entropy Loss\n‚Ä¢ The model output yÃÇ : The predicted\nprobability that ùë¶=1, given the input ùë•\nand weights ùë§\n‚Ä¢ The error (loss) is the average of the\nerrors over the m data points.\n‚Ä¢ The error for the individual data point is\nsmall if the predicted value yÃÇ is close to\nthe actual value y\n‚Ä¢ Log Loss (Binary Cross-Entropy Loss):\nTypically used for binary classification\nproblems where there are only two\nclasses (e.g., 0 and 1).'}
{'slide_number': 37, 'text': 'Non-linear (polynomial) (logistic) regression\n‚Ä¢ Goal: To capture complex, non-linear relationships that cannot\nbe modeled with simple linear (or logistic) regression.\n‚Ä¢ Do polynomial transformations of the input features (e.g., x2,\nx3, x x , sqrt(x)‚Ä¶) to capture non-linearity.\ni j\nAdvantages\n‚Ä¢ Flexibility: Can model complex relationships in data that linear\nmodels cannot capture.\n‚Ä¢ Interpretability: Coefficients can still be interpreted.\nDisadvantages\n‚Ä¢ Overfitting: Higher degrees can lead to overfitting, especially\nwith limited data.\n‚Ä¢ Increased Complexity: More features (combinations) increase\ncomputation and can complicate model interpretation.\nSee notebook polynomial_regression.ipynb for details.'}
{'slide_number': 38, 'text': 'Regularization of Linear and Logistic Regression\n‚Ä¢ What is Regularization?\n‚Ä¢ Prevents overfitting by adding a penalty to the loss function: Error = Loss + Penalty\n‚Ä¢ Enhances model generalization on unseen data.\nRegularization Type Description Penalty Term\nEncourages sparsity in weights\nLasso (L1 Regularization)\n(some weights can be zero).\nPenalizes large weights, keeping all\nRidge (L2 Regularization)\nweights small but non-zero.\nCombines L1 and L2 regularization\nElastic Net benefits, promoting sparsity while\nmanaging multicollinearity.'}
